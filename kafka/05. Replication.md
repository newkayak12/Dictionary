## 5. Replication이란?

### 개념

- Partition의 **복제본을 여러 Broker에 저장**
- 데이터 손실 방지와 **고가용성** 보장
- **Replication Factor**로 복제본 수 설정 (보통 3)

### Leader/Follower 구조

- **Leader Partition**: 모든 읽기/쓰기 요청 처리
- **Follower Partition**: Leader의 데이터를 지속적으로 복제
- Leader 장애 시 Follower 중 하나가 새 Leader로 선출

### 복제 과정

- **Pull-based**: Follower가 Leader에서 데이터 가져옴
- **비동기 복제**: Leader가 즉시 응답, Follower는 나중에 동기화
- **Fetch Request**: Follower가 주기적으로 Leader에게 요청


---
### **1. Replication Factor 설정**

- **RF=1**: 복제 없음, 성능 최고/안정성 최악
- **RF=3**: 일반적 권장값, 2개 Broker 장애까지 허용
- **RF=5**: 금융권 등 초고가용성 요구 환경

### **2. Leader Election 전략**

- **Clean Leader Election**: ISR 내에서만 Leader 선출 (데이터 안전)
- **Unclean Leader Election**: ISR 밖에서도 선출 (가용성 우선)
- **Preferred Leader**: 원래 Leader로 복구 시도

### **3. 일관성 수준**

- **Eventual Consistency**: 결국 모든 Replica 동일해짐
- **Strong Consistency**: acks=all로 모든 ISR 동기화 대기
- **Read Your Writes**: Producer가 쓴 데이터는 즉시 읽기 가능

### **4. Split-Brain 방지**

- **Controller Election**: ZooKeeper/KRaft로 단일 Controller 보장
- **Quorum**: 과반수 Broker가 살아있어야 동작
- **Fencing**: 이전 Leader의 쓰기 차단

### **5. Cross-AZ Replication**

- **Rack Awareness**: 동일 랙 장애 대비 분산 배치
- **Availability Zone**: 물리적 격리를 통한 장애 허용
- **Network Latency**: AZ 간 지연시간이 성능에 미치는 영향

### **6. 복제 성능 최적화**

- **replica.fetch.max.bytes**: Follower가 한 번에 가져올 데이터 크기
- **replica.lag.time.max.ms**: ISR 제외 기준 시간
- **num.replica.fetchers**: 병렬 복제 스레드 수

---
## ⚠️ ISR?
### 개념
- **In-Sync Replicas**: Leader와 동기화 상태인 Replica들
- Leader + 동기화된 Follower들의 집합
- **실제로 데이터를 읽고 쓸 수 있는** 신뢰할 수 있는 Replica들
- `acks=all`의 판단을 전체로 하는가? 아니면 ISR에서만 하는가?
- 오래된 데이터를 가진 Replica가 Leader가 되는 것을 막을 수 있다.
	- 데이터 손실 막는다.
- 살아있고 최신 데이터를 가진 Replica만 신뢰한다.
### ISR vs All Replicas
- **All Replicas**: Replication Factor로 설정된 모든 복제본
- **ISR**: 그 중 실제로 동기화 상태인 Replica만
- 장애/네트워크 이슈로 ISR < All Replicas 될 수 있음
### ISR 포함/제외 조건

**포함 조건**
- **replica.lag.time.max.ms** 내에 Leader에게 Fetch 요청한 Replica
- 기본값 30초, 이 시간 내 요청 없으면 ISR에서 제외
- Leader는 항상 ISR에 포함

**제외 조건**
- 네트워크 지연으로 Fetch 요청 늦음
- Follower Broker 장애
- 디스크 I/O 과부하로 복제 지연

### ISR과 데이터 안전성
- **Consumer 읽기 제한**: ISR 모든 Replica가 가진 데이터까지만 읽기 가능
- **High Water Mark**: ISR 중 최소 Offset 위치
- **Leader 선출**: ISR 내에서만 새 Leader 선출 가능

---

### **1. ISR 관리 정책**
- **Dynamic ISR**: 실시간으로 ISR 멤버십 변경
- **Shrinking**: 지연되는 Replica 자동 제외
- **Expanding**: 복구된 Replica 자동 추가
- **Controller 역할**: ISR 변경을 모든 Broker에 통지

### **2. Min ISR 설정 (중요!)**
- `min.insync.replicas=2`: 최소 2개 ISR 유지 필요
- **ISR < Min ISR 시**: Producer에게 **NotEnoughReplicas** 예외
- **가용성 vs 일관성**: 안전성을 위해 쓰기 거부

### **3. acks와 ISR의 관계**
- `acks=all`: ISR의 **모든** Replica가 응답해야 성공
- **ISR=1 (Leader만)**: acks=all이어도 Leader만 확인
- **성능 영향**: ISR 크기가 클수록 응답 시간 증가

### **4. ISR 모니터링 지표 (필수)**
- **Under Replicated Partitions**: ISR < Replication Factor인 Partition 수
- **ISR Shrinks/Expands**: ISR 변경 빈도 (불안정성 지표)
- **Replica Lag**: Follower의 지연 정도
- **Min ISR Violations**: `min.insync.replicas` 위반 횟수

### **5. 장애 시나리오별 동작**
- **Leader 장애**: ISR 내 Follower가 새 Leader
- **ISR 크기 = 1**: 데이터 보존 vs 가용성 선택 필요
- **모든 ISR 장애**: Unclean Leader Election 정책에 따라 결정

### **6. 네트워크 파티션 대응**
- **Split ISR**: 네트워크 분할 시 ISR도 분할
- **Majority Quorum**: 과반수 ISR만 활성 상태 유지
- **Recovery Protocol**: 네트워크 복구 시 ISR 재구성

### **7. ISR 최적화 전략**
- **Cross-AZ Balance**: 여러 AZ에 ISR 분산 배치
- **Network 최적화**: Broker 간 네트워크 지연 최소화
- **Disk I/O 튜닝**: 복제 성능 향상으로 ISR 안정성 확보
- **Monitoring & Alerting**: ISR 변경 시 즉시 알림