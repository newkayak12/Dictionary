## 왜 Kafka Consumer에서 병렬 처리를 지원하지 않는가?

### 1. Offset 관리의 근본적 문제

#### 현재 Kafka 전제조건
- **Sequential Commit**: offset은 순차적으로만 commit 가능
- **Gap 없는 진행**: offset 100이 commit되면 0~99는 모두 처리 완료 의미
- **단순한 로직**: consumer restart 시 마지막 commit된 offset부터 재시작

#### 병렬 처리 시 발생하는 문제
- **처리 완료 순서 불일치**: 메시지 1,2,3을 병렬 처리 → 2,3 완료, 1 아직 처리 중
- **Commit 불가능**: offset 3을 commit하려면 1,2가 완료되어야 함
- **복잡한 State 관리**: 어떤 offset이 완료되었는지 bitmap/map으로 추적 필요
- **Restart 복잡성**: 재시작 시 어디서부터 처리해야 할지 계산 복잡

### 2. Kafka 설계 철학과 충돌

#### "Simple and Fast" 원칙
- **단순함 우선**: Kafka는 단순하고 빠른 메시징에 집중
- **복잡성 외부화**: 고급 기능은 클라이언트 라이브러리에서 처리
- **Core 기능 집중**: Produce, Consume, Replicate에만 집중

#### "One Size Doesn't Fit All"
- **다양한 병렬 전략**: Key 기반, 완전 병렬, 파티션 내 순서 등
- **성능 트레이드오프**: 병렬 처리 오버헤드 vs 처리량 증가
- **사용자별 요구사항**: 순서 보장 수준이 케이스마다 다름

### 3. 구현 복잡성의 구체적 예시

#### Error Handling 복잡성
- **부분 실패**: 병렬 처리 중 일부 메시지만 실패 시 처리 방법
- **Retry 전략**: 실패한 메시지의 재시도가 순서에 미치는 영향
- **Dead Letter Queue**: 실패 메시지 처리를 위한 추가 인프라 필요

#### Resource Management
- **Thread Pool 관리**: 적정 스레드 수 결정 알고리즘
- **Memory 사용량**: 처리 중인 메시지들의 버퍼 관리
- **Backpressure**: 처리 속도 < 유입 속도일 때 제어 메커니즘

### 4. 현실적인 대안의 존재

#### 기존 확장 방법들
- **Partition 증가**: 가장 자연스러운 확장 방법
- **Consumer Group 확장**: 인스턴스 추가로 해결
- **외부 라이브러리**: Parallel Consumer 같은 전문 라이브러리