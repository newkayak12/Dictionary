# Outbox Pattern과 Saga Pattern

## 배경: 분산 시스템에서의 데이터 일관성 문제

마이크로서비스 아키텍처에서는 각 서비스가 자체 데이터베이스를 가진다. 이런 환경에서 여러 서비스에 걸친 작업의 일관성을 보장하는 것이 핵심 과제다.

전통적인 모놀리식 환경에서는 단일 데이터베이스 트랜잭션으로 해결되던 문제가, 분산 환경에서는 완전히 다른 접근이 필요하다.

---

## Outbox Pattern

### Dual Write Problem

분산 시스템에서 가장 흔하게 마주치는 문제다. 데이터베이스에 데이터를 저장하면서 동시에 메시지 브로커에 이벤트를 발행해야 하는 상황을 생각해보자.

```kotlin
@Transactional
fun createOrder(request: OrderRequest): Order {
    val order = orderRepository.save(Order(
        customerId = request.customerId,
        items = request.items,
        totalAmount = request.totalAmount
    ))
    
    // 여기서 문제 발생
    kafkaTemplate.send("order-created", OrderCreatedEvent(order.id))
    
    return order
}
```

이 코드는 언뜻 문제없어 보이지만, 실제로는 여러 실패 케이스가 존재한다.

#### 케이스 1: 데이터베이스 저장 성공, 메시지 발행 실패

```
1. orderRepository.save() 성공
2. DB 트랜잭션 커밋 완료
3. kafkaTemplate.send() 호출
4. 네트워크 장애로 Kafka 브로커 도달 실패
```

결과: 주문은 DB에 저장되었지만, 다른 서비스들은 이 주문에 대해 알지 못한다. 결제 서비스도, 배송 서비스도 반응하지 않는다.

#### 케이스 2: 메시지 발행 성공, 데이터베이스 커밋 실패

```
1. orderRepository.save() 성공 (아직 커밋 전)
2. kafkaTemplate.send() 성공
3. DB 커밋 시도
4. 제약 조건 위반 또는 기타 오류로 롤백
```

결과: Kafka에는 이벤트가 발행되어 다른 서비스들이 처리를 시작했지만, 실제로 주문은 존재하지 않는다.

#### 케이스 3: 중복 메시지 발행

```
1. orderRepository.save() 성공
2. kafkaTemplate.send() 성공
3. Kafka 브로커로부터 ack 수신 대기 중 타임아웃
4. 애플리케이션은 실패로 간주하고 재시도
5. 실제로는 첫 번째 메시지가 정상 발행되어 있음
```

결과: 동일한 주문 생성 이벤트가 두 번 발행되어, 컨슈머가 중복 처리할 위험이 있다.

이 문제의 본질은 **데이터베이스 트랜잭션과 메시지 발행이 서로 다른 시스템**이라는 점이다. JDBC 트랜잭션은 DB에만 적용되고, Kafka 발행은 별도의 네트워크 I/O다. 두 작업을 원자적으로 묶을 방법이 없다.

### Outbox Pattern의 작동 원리

Outbox Pattern은 이 문제를 해결하기 위해 메시지 발행을 데이터베이스 트랜잭션 안으로 끌어들인다.

핵심 아이디어: **메시지를 별도 테이블에 먼저 저장하고, 나중에 발행한다.**

#### 테이블 설계

```sql
CREATE TABLE outbox_events (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    aggregate_type VARCHAR(100) NOT NULL,
    aggregate_id VARCHAR(100) NOT NULL,
    event_type VARCHAR(100) NOT NULL,
    payload JSON NOT NULL,
    status VARCHAR(20) DEFAULT 'PENDING',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    published_at TIMESTAMP NULL,
    retry_count INT DEFAULT 0,
    last_error TEXT NULL,
    
    INDEX idx_status_created (status, created_at),
    INDEX idx_aggregate (aggregate_type, aggregate_id),
    UNIQUE KEY uk_deduplication (aggregate_type, aggregate_id, event_type, created_at)
);
```

각 컬럼의 역할:
- `aggregate_type`, `aggregate_id`: 어떤 엔티티에 대한 이벤트인지 (예: Order, Payment)
- `event_type`: 이벤트 종류 (OrderCreated, OrderCancelled 등)
- `payload`: 실제 이벤트 데이터 (JSON)
- `status`: PENDING, PUBLISHED, FAILED
- `retry_count`: 재시도 횟수 추적
- `last_error`: 실패 시 오류 내용 저장

#### 저장 로직

```kotlin
@Transactional
fun createOrder(request: OrderRequest): Order {
    val order = orderRepository.save(Order(
        customerId = request.customerId,
        items = request.items,
        totalAmount = request.totalAmount
    ))
    
    outboxRepository.save(OutboxEvent(
        aggregateType = "Order",
        aggregateId = order.id.toString(),
        eventType = "OrderCreated",
        payload = objectMapper.writeValueAsString(OrderCreatedEvent(
            orderId = order.id,
            customerId = order.customerId,
            totalAmount = order.totalAmount
        ))
    ))
    
    return order
}
```

이제 두 개의 INSERT가 모두 동일한 데이터베이스 트랜잭션 안에서 실행된다. 둘 다 성공하거나, 둘 다 실패한다. 중간 상태는 존재하지 않는다.

#### 발행 전략

저장된 이벤트를 실제로 메시지 브로커로 발행하는 방법은 크게 세 가지다.

##### 1. Polling 방식

가장 직관적인 방법이다. 주기적으로 outbox 테이블을 조회해서 PENDING 상태인 이벤트를 찾아 발행한다.

```kotlin
@Component
class OutboxMessageRelay(
    private val outboxRepository: OutboxRepository,
    private val kafkaTemplate: KafkaTemplate<String, String>,
    private val objectMapper: ObjectMapper
) {
    
    companion object {
        private val logger = LoggerFactory.getLogger(OutboxMessageRelay::class.java)
        private const val BATCH_SIZE = 100
        private const val MAX_RETRY = 5
    }
    
    @Scheduled(fixedDelay = 1000)
    @Transactional
    fun relayMessages() {
        val events = outboxRepository.findByStatusOrderByCreatedAt(
            status = "PENDING",
            limit = BATCH_SIZE
        )
        
        if (events.isEmpty()) {
            return
        }
        
        logger.info("Processing ${events.size} outbox events")
        
        events.forEach { event ->
            try {
                val sendResult = kafkaTemplate.send(
                    event.aggregateType.lowercase(),
                    event.aggregateId,
                    event.payload
                ).get(5, TimeUnit.SECONDS)
                
                event.status = "PUBLISHED"
                event.publishedAt = Instant.now()
                
                logger.debug("Published event: ${event.id}")
                
            } catch (e: Exception) {
                event.retryCount++
                event.lastError = e.message
                
                if (event.retryCount >= MAX_RETRY) {
                    event.status = "FAILED"
                    logger.error("Event ${event.id} failed after $MAX_RETRY retries", e)
                    // DLQ로 전송하거나 알림 발송
                    sendToDeadLetterQueue(event)
                } else {
                    logger.warn("Event ${event.id} failed, retry ${event.retryCount}/$MAX_RETRY", e)
                }
            }
        }
    }
    
    private fun sendToDeadLetterQueue(event: OutboxEvent) {
        kafkaTemplate.send("outbox-dlq", event.id.toString(), event.payload)
    }
}
```

Polling 방식의 특징:
- 구현이 간단하다. 추가 인프라 없이 애플리케이션 코드만으로 동작한다.
- 데이터베이스에 부하를 준다. SELECT 쿼리가 지속적으로 실행된다.
- 실시간성이 떨어진다. Polling 주기만큼 지연이 발생한다.

최적화 포인트:
```kotlin
// 1. 배치 크기 조정
// 너무 작으면: 처리량 낮음, DB 왕복 증가
// 너무 크면: 메모리 사용량 증가, 처리 시간 길어짐
private const val BATCH_SIZE = 100

// 2. 인덱스 활용
// (status, created_at) 복합 인덱스로 조회 최적화
WHERE status = 'PENDING' ORDER BY created_at LIMIT 100

// 3. Partition 전략 (대용량)
// created_at 기준으로 테이블 파티셔닝
CREATE TABLE outbox_events (...)
PARTITION BY RANGE (TO_DAYS(created_at)) (
    PARTITION p202501 VALUES LESS THAN (TO_DAYS('2025-02-01')),
    PARTITION p202502 VALUES LESS THAN (TO_DAYS('2025-03-01'))
);
```

##### 2. CDC (Change Data Capture) 방식

데이터베이스의 변경 로그를 실시간으로 읽어서 이벤트를 발행한다. Debezium이 대표적인 도구다.

Debezium 설정 예시:
```json
{
  "name": "order-outbox-connector",
  "config": {
    "connector.class": "io.debezium.connector.mysql.MySqlConnector",
    "database.hostname": "mysql-host",
    "database.port": "3306",
    "database.user": "debezium",
    "database.password": "password",
    "database.server.id": "184054",
    "database.server.name": "order-service",
    "database.include.list": "order_db",
    "table.include.list": "order_db.outbox_events",
    
    "transforms": "outbox",
    "transforms.outbox.type": "io.debezium.transforms.outbox.EventRouter",
    "transforms.outbox.table.field.event.id": "id",
    "transforms.outbox.table.field.event.key": "aggregate_id",
    "transforms.outbox.table.field.event.type": "event_type",
    "transforms.outbox.table.field.event.payload": "payload",
    
    "database.history.kafka.bootstrap.servers": "kafka:9092",
    "database.history.kafka.topic": "schema-changes.order"
  }
}
```

작동 원리:
1. MySQL의 binlog를 실시간으로 구독한다
2. outbox_events 테이블에 INSERT가 발생하면 즉시 감지한다
3. 변경 내용을 파싱해서 Kafka로 발행한다
4. 애플리케이션 코드는 전혀 관여하지 않는다

장점:
- 실시간성이 높다. INSERT 발생 즉시 이벤트가 발행된다.
- 애플리케이션 부하가 없다. 별도 프로세스가 처리한다.
- 정확성이 보장된다. 커밋된 트랜잭션만 읽는다.

단점:
- 인프라 복잡도가 증가한다. Kafka Connect, Debezium 설정 및 운영 필요.
- binlog 설정이 필요하다. MySQL의 경우 ROW 포맷 binlog 활성화.
- 데이터베이스 의존성이 생긴다. binlog 보관 정책, 디스크 용량 고려.

##### 3. Transaction Log Tailing

binlog나 WAL(Write-Ahead Log)을 직접 파싱하는 방식이다. CDC 도구 없이 직접 구현하거나, 특수한 요구사항이 있을 때 사용한다.

```kotlin
class BinlogTailer(
    private val kafkaTemplate: KafkaTemplate<String, String>
) {
    private val logger = LoggerFactory.getLogger(BinlogTailer::class.java)
    
    fun start() {
        val client = BinaryLogClient(
            "mysql-host",
            3306,
            "replication_user",
            "password"
        )
        
        client.registerEventListener { event ->
            when (event.data) {
                is WriteRowsEventData -> handleInsert(event.data as WriteRowsEventData)
                is UpdateRowsEventData -> handleUpdate(event.data as UpdateRowsEventData)
                else -> {}